<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[RSS Feed | Mayank Raj]]></title><description><![CDATA[Solutions Architect with experience in building at scale in applied AI/ML, Big Data, Serverless and more. AWS Certified Solutions Architect Professional.]]></description><link>https://mayankraj.com</link><generator>GatsbyJS</generator><lastBuildDate>Sat, 10 Aug 2024 10:14:15 GMT</lastBuildDate><item><title><![CDATA[Journey Through the Silicon : Network communications via Ephemeral Ports]]></title><description><![CDATA[Do you ever stop to think about the tiny marvels of technology that make our digital world go 'round? We're diving into the building blocks‚Ä¶]]></description><link>https://mayankraj.com/blog/ephemeral-ports</link><guid isPermaLink="false">https://mayankraj.com/blog/ephemeral-ports</guid><pubDate>Sun, 03 Sep 2023 12:13:00 GMT</pubDate><content:encoded>&lt;p&gt;Do you ever stop to think about the tiny marvels of technology that make our digital world go &apos;round? We&apos;re diving into the building blocks of the tech universe, unraveling the mysteries behind what enables you to read this very article. We&apos;re talking DNS, ephemeral ports, proxies, tunnels, and more‚Äîthese are the unsung heroes ensuring data flows seamlessly from one device to another on your network.&lt;/p&gt;
&lt;p&gt;Today, our spotlight is on ephemeral ports. These unsung heroes are the reason you can have multiple online conversations at once. Imagine only being able to chat with one friend at a time‚Äîhow dull would that be?&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;The Basics: Can You Juggle Two Conversations?&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Let&apos;s put you in the spotlight. Have you ever chatted with more than one friend simultaneously? Of course, you have! Picture a scenario where you&apos;re conversing with each of them on different topics. Now, think about how you manage that. Let&apos;s start with a situation where these conversations are happening over text. It&apos;s as simple as opening separate chat windows for each conversation. You effortlessly switch between these windows, seamlessly adding to each discussion. With minimal effort, you maintain the context of each conversation and respond appropriately. The topics can vary widely, but you&apos;ve got it all under control.&lt;/p&gt;
&lt;p&gt;Now, shift gears and imagine you&apos;re doing this in person. Not so challenging, is it?&lt;/p&gt;
&lt;p&gt;Replace those chat windows with the faces of your friends, and you can still smoothly engage in two or more parallel conversations at the same time.&lt;/p&gt;
&lt;p&gt;Let&apos;s dissect what&apos;s happening here: You initiate each conversation, creating a context (even if it&apos;s subconscious) for that specific chat. Without breaking a sweat, you receive responses and place them neatly within the corresponding context. When it&apos;s time to respond, you effortlessly switch back to the relevant context and continue the conversation.&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;Ephemeral Ports: Where Your Tech Devices Get Playful&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Have you ever wondered how your tech gadgets, be it your mobile, laptop, or even your trusty smartwatch, manage to mimic human-like communication? Well, behind the scenes, they rely on something called &quot;ephemeral ports&quot; to keep their digital conversations flowing smoothly. But before we dive into this world of tech wizardry, let&apos;s take a quick detour to refresh our memory on what ports are all about.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Ports: The Gateways to Digital Conversations&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Think of ports as the doors to a bustling digital building, the faces in a crowd, or even the chat windows in our digital lives. They are the identifiers that machines use to keep track of different ongoing conversations. Every message that goes out or comes in gets neatly sorted into these virtual buckets, and it&apos;s the operating system&apos;s job to manage and process the data within them like a maestro conducting a symphony.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Numbers, Numbers Everywhere&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Now, here&apos;s where it gets interesting. When you type in a web address like &quot;&lt;strong&gt;&lt;a href=&quot;https://mayankraj.com/&quot;&gt;https://mayankraj.com/&lt;/a&gt;&lt;/strong&gt;&quot; (a little shameless plug never hurts, right?), you&apos;re actually making a request to &quot;&lt;strong&gt;&lt;a href=&quot;https://mayankraj.com/&quot;&gt;https://mayankraj.com:443/&lt;/a&gt;&lt;/strong&gt;&quot;. That &quot;:443&quot; at the end? That&apos;s the port number! These numbers range from 0 to 65,353. The first 1023 are reserved for super common TCP/IP applications, aptly named &quot;well-known ports.&quot; There are a few global favorites, like 22 for Secure Socket Shell (SSH), 80 for Hypertext Transfer Protocol (HTTP), 443 for the super-secure Hypertext Transfer Protocol Secure (HTTPS), and many more. Then come the &quot;registered ports,&quot; ranging from 1,024 to 49,151, where applications on your operating system can request to listen in. Ports like 8000 or 8080 are often used for local development. Finally, the last block, from 49,152 to 65,535, houses the dynamic ports, reserved for short-lived, on-the-fly communications.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The Ephemeral Dance&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In the grand scheme of things, when your favorite app wants to talk to anything else, be it on your local network or across the vast internet, it starts by asking the operating system for a free port. Usually, it goes for one from the dynamic port range, but it can also venture into the reserved territory. The OS kindly grants it a port, let&apos;s say 57000, which means any data received on this port will be sent straight to that application.&lt;/p&gt;
&lt;p&gt;Now, when our app wants to chat with another digital entity (say, a web server), it makes a request on the well-known port of the destination (like 443 for HTTPS). But here&apos;s the fun part ‚Äì it also includes the port number it received from the OS as its return address, which is 57000 in our case. The destination, our trusty web server, gets the message on port 443, processes it gracefully, constructs a reply, and sends it off to the port number 57000. When the OS on the other end receives this data packet on 57000, it&apos;s like the final act in a fantastic play; it forwards it to the waiting application. This special 57000 port? That, my friends, is what we call an &quot;ephemeral port.&quot;&lt;/p&gt;
&lt;p&gt;So, the next time you see your tech devices communicating seamlessly, remember the ephemeral ports doing a lively dance behind the scenes, ensuring that your digital world stays beautifully connected. It&apos;s all part of the delightful play that is modern technology! üéâüåê&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Data archival on cloud and how to not do it]]></title><description><![CDATA[Making data-driven decisions is the new norm. It won't come as a surprise that the rate at which we are generating data has gone up. As the‚Ä¶]]></description><link>https://mayankraj.com/blog/data-archival</link><guid isPermaLink="false">https://mayankraj.com/blog/data-archival</guid><pubDate>Fri, 02 Jun 2023 18:30:00 GMT</pubDate><content:encoded>&lt;p&gt;Making data-driven decisions is the new norm. It won&apos;t come as a surprise that the rate at which we are generating data has gone up. As the volume of data continues to grow exponentially, businesses are increasingly turning to cloud storage for efficient and scalable archiving solutions. The cloud offers numerous advantages, such as cost-effectiveness, flexibility, and easy accessibility. However, archiving data in the cloud requires careful consideration and planning to ensure data integrity, security, and long-term accessibility. In this blog post, we will explore some common mistakes to avoid when archiving data in the cloud.&lt;/p&gt;
&lt;p&gt;In this blog, we will look at Amazon S3 Glacier which is a popular cloud storage service provided by Amazon Web Services (AWS) that offers durable, secure, and cost-effective storage for long-term data archiving and backup. While S3 Glacier provides numerous benefits, it is important to understand the scenarios in which it may not be the ideal choice. In this blog post, we will delve into the strengths of S3 Glacier and highlight situations where alternative storage solutions might be more appropriate.&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;Key Areas to Look Out for&lt;/h2&gt;
&lt;p&gt;&lt;ins&gt;&lt;strong&gt;The need for Data Classification&lt;/strong&gt;&lt;/ins&gt; is one of the key mistakes organizations make when archiving data in the cloud. It may seem logical but try to think about the last time your team put in conscious effort in classifying the data properly. Not all data is created equal, and without proper classification, it becomes difficult to prioritize data for archiving, apply appropriate retention policies, and allocate storage resources effectively. Invest time in understanding your data, identifying its value, and categorizing it based on its sensitivity, compliance requirements, and business importance.&lt;/p&gt;
&lt;p&gt;Overlooking the &lt;ins&gt;&lt;strong&gt;backup strategy&lt;/strong&gt;&lt;/ins&gt; often leads to bad experiences down the line. Archiving data does not mean it&apos;s exempt from the risk of loss or corruption. Failing to implement a robust backup and recovery strategy is a grave mistake. Many organizations assume that cloud service providers automatically handle backups, but this is not always the case. Cloud providers may offer infrastructure-level redundancy, but it&apos;s essential to have your data backup strategy in place to protect against accidental deletion, data corruption, or service provider failures. Regularly test your backup and recovery processes to ensure they are effective and reliable.&lt;/p&gt;
&lt;p&gt;When in cloud &lt;ins&gt;&lt;strong&gt;compliance&lt;/strong&gt;&lt;/ins&gt; becomes even more important. Compliance regulations and legal requirements dictate how long certain data must be retained. Ignoring or overlooking these policies when archiving data can lead to serious consequences, such as legal liabilities or financial penalties. Ensure you understand the specific data retention requirements for your industry and region. Implement proper retention policies and procedures, and regularly review and update them to stay compliant with evolving regulations.&lt;/p&gt;
&lt;p&gt;You might also be overlooking data validation and integrity checks. &lt;ins&gt;&lt;strong&gt;Data integrity&lt;/strong&gt;&lt;/ins&gt; is crucial for successful long-term archiving. Neglecting to perform regular data validation and integrity checks can result in silent data corruption that goes undetected until it&apos;s too late. Implement checksums, hash functions, or other integrity validation mechanisms to ensure data remains intact and unaltered during the archiving process. Regularly validate archived data to identify and rectify any integrity issues promptly.&lt;/p&gt;
&lt;p&gt;From Day-0, keep an eye on the &lt;ins&gt;&lt;strong&gt;Long-Term Storage Costs&lt;/strong&gt;&lt;/ins&gt;. While cloud storage offers scalability and flexibility, it&apos;s important to consider the long-term costs associated with archiving data. Cloud storage costs can accumulate over time, especially for large-scale archiving projects. Evaluate different storage options, including lower-cost tiers specifically designed for archiving, and consider a mix of storage solutions to optimize cost-effectiveness. Additionally, periodically review and analyze your archiving needs to identify and remove obsolete or unnecessary data.&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;S3 Glacier&lt;/h2&gt;
&lt;p&gt;S3 Glacier is a highly advantageous option for archiving data in the cloud due to its cost-effectiveness, durability, availability, security, and integration capabilities. It offers a low-cost storage solution for long-term data retention, making it suitable for infrequently accessed data without immediate retrieval requirements. With a remarkable durability of 99.999999999% (11 nines), data stored in S3 Glacier is spread across multiple facilities to ensure high availability. Security is ensured through server-side encryption, access controls, and seamless integration with AWS Identity and Access Management (IAM). Moreover, S3 Glacier seamlessly integrates with S3 lifecycle policies, enabling automated transitions from hot storage tiers to Glacier based on user-defined rules.&lt;/p&gt;
&lt;h2&gt;Limitations and When Not to Use S3 Glacier:&lt;/h2&gt;
&lt;p&gt;Despite its advantages, there are certain scenarios where S3 Glacier might not be the optimal storage solution.
If you have data that requires frequent or real-time access, S3 Glacier&apos;s retrieval times (ranging from minutes to hours) may not meet your requirements. In such cases, consider using other storage classes like S3 Standard or S3 Intelligent Tiering. S3 Glacier is optimized for large file sizes. If you predominantly work with small files, the overhead associated with Glacier&apos;s minimum storage duration and retrieval costs might outweigh the benefits. Consider other storage options like S3 One Zone-IA or S3 Standard-IA for smaller files.&lt;/p&gt;
&lt;p&gt;If you need short-term storage for data that will be frequently accessed or modified, S3 Glacier is not the appropriate choice. Instead, opt for storage classes like S3 Standard or S3 Intelligent-Tiering, which offer low-latency and high-performance characteristics. While S3 Glacier provides expedited retrieval options, the associated costs can be higher. If you have strict recovery time objectives (RTOs) and need rapid access to your data, alternatives like S3 Standard orIntelligent Tieringring will better suit your needs.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;In conclusion, if you are looking for a cost-effective and scalable solution to manage the increasing volume of data then archiving data in the cloud could be a great option. But to ensure successful archiving, you should make sure to look into a few aspects. Proper data classification is essential for prioritizing data, applying retention policies, and so is effectively allocating storage resources. Implementing a robust strategy to back up the data, including regular testing, protects against data loss and corruption. Compliance with data retention requirements and regular validation checks ensure data integrity and regulatory adherence cannot be ignored. Considering long-term storage costs and periodically reviewing archiving needs optimizes cost-effectiveness.&lt;/p&gt;
&lt;p&gt;Amazon S3 Glacier is a great option but remember that it is just that - an option. I would use Glacier with my eyes closed for certain use cases but certainly not for all of them. Once you know of the limitations of the tool, you can make better and more informed decisions. For some cases, alternative storage classes like S3 Standard or S3 Intelligent Tiering are more appropriate. Short-term storage needs with frequent access or modification are better served by S3 Standard or S3 Intelligent-Tiering, which offer low-latency and high-performance characteristics. Considering recovery time objectives and the associated costs, organizations can make informed decisions about the most suitable storage option for their specific requirements.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Zero Day Vulnerabilities and You : Introduction]]></title><description><![CDATA[You may not have realised it but there are a handful if not more zero day vurlnerabilities running on the very device you are holding‚Ä¶]]></description><link>https://mayankraj.com/blog/zero-day-vulnerabilities-and-you-introduction</link><guid isPermaLink="false">https://mayankraj.com/blog/zero-day-vulnerabilities-and-you-introduction</guid><pubDate>Wed, 15 Feb 2023 16:53:24 GMT</pubDate><content:encoded>&lt;p&gt;You may not have realised it but there are a handful if not more zero day vurlnerabilities running on the very device you are holding. Weather that is a mobile device, laptop, tablet or even your smart fridge. you can get a grip on their seriousness by knowing that Zero day vurlnerabilties are traded for hundreeds if not millions of dollars among Cyber Criminals and nation state actors.&lt;/p&gt;
&lt;p&gt;To name a few, attacks like Wanacry which affected hundreds of thousands of computers in over 150 countries in May 2017, Stuxne which used a sophisticated piece of malware that targeted Iran&apos;s nuclear program and was discovered in 2010 were done with help of one or more Zero Day Vurnerability at it&apos;s core.&lt;/p&gt;
&lt;p&gt;In this series, I will attempt to tear apart a few such attacks. We will look at how the attack was caries out, what the exploit was, it&apos;s impact and how it was eventually fixed. The language of the articles in the series will ensure that any and everyone will be able to appreciate the execution behind these attacks, in makign them happen and fixing them. This is the most facinating part for me and is what I want to share.&lt;/p&gt;
&lt;br/&gt;
&lt;hr&gt;
&lt;!-- ## But first, What is a Zero Day Vulnerability ? --&gt;</content:encoded></item><item><title><![CDATA[Unique Quirks of DynamoDB: Things you will notice when building at scale]]></title><description><![CDATA[DynamoDB is part of the Database family of AWS. It sits beside the heavyweights like RDS, Redshift, etc. It is a fully managed NoSQL‚Ä¶]]></description><link>https://mayankraj.com/blog/dynamodb-quirks</link><guid isPermaLink="false">https://mayankraj.com/blog/dynamodb-quirks</guid><pubDate>Sat, 28 Jan 2023 18:30:00 GMT</pubDate><content:encoded>&lt;p&gt;DynamoDB is part of the Database family of AWS. It sits beside the heavyweights like RDS, Redshift, etc. It is a fully managed NoSQL database. The core value of DynamoDB is that it provides a high-performance storage solution for applications that require low-latency access to large amounts of data. Above all, it is scalable and reliable, even at large data volumes in tunes of a couple of hundred gigabytes.&lt;/p&gt;
&lt;p&gt;Above all, it&apos;s a managed solution. While that is great news to start with but also means that you don&apos;t get to finetune it when the need arises. So you have to make sure that from Day 0, right from the time when you are designing the database patterns, you also design for the unique behavior of DynamoDB.&lt;/p&gt;
&lt;br/&gt;
&lt;hr&gt;
&lt;p&gt;&lt;ins&gt;&lt;strong&gt;Flexible Schema&lt;/strong&gt;&lt;/ins&gt; is the headlining feature of the database, like any other NoSQL database. Flexible schemas sound like great news but when you go from a few records to a billion, it can come back to bite you. The flexible schema allows you to store items with varying attributes within the same table. This provides great flexibility when dealing with evolving data structures. For example, let&apos;s say you have an e-commerce application where different product categories have different attributes. With DynamoDB, you can store products of various categories in a single table, without needing to define a fixed schema upfront.
DynamoDB indexes play a big role in how you make use of this schema. Without an index, it&apos;s as good as you are not using a database but reading the whole data for every query from a large json file.&lt;/p&gt;
&lt;p&gt;&lt;ins&gt;&lt;strong&gt;Secondary Indexes&lt;/strong&gt;&lt;/ins&gt; will quickly become your friends when you scale. They provide flexible querying capabilities. These indexes can be global, spanning the entire table, or local, limited to a specific partition. Secondary indexes allow you to query your data using different attributes, enhancing the flexibility and efficiency of your application.&lt;/p&gt;
&lt;p&gt;Let&apos;s take an example wherein you are building a social media application and need to retrieve posts by both creation date and user ID. By creating a global secondary index on the user ID attribute, you can efficiently query the DynamoDB table to retrieve all posts made by a particular user. Integrating DynamoDB with AWS AppSync and AWS Amplify can further simplify the development process by providing managed GraphQL APIs for your frontend applications, seamlessly integrating with DynamoDB&apos;s secondary indexes.&lt;/p&gt;
&lt;p&gt;&lt;ins&gt;&lt;strong&gt;Transparent Scaling&lt;/strong&gt;&lt;/ins&gt; is a big draw of DynamoDB. It dynamically adjusts its capacity based on the workload. This eliminates the need for manual provisioning and ensures consistent performance as your application&apos;s demand fluctuates. Scaling can be done both vertically (throughput per partition) and horizontally (number of partitions).&lt;/p&gt;
&lt;p&gt;Suppose you have a real-time analytics application that experiences varying traffic patterns throughout the day. By integrating DynamoDB with Amazon CloudWatch and AWS Application Auto Scaling, you can monitor the workload and automatically adjust the provisioned capacity of your DynamoDB tables. This enables your application to handle high-traffic periods without compromising performance or incurring unnecessary costs during low-traffic periods.&lt;/p&gt;
&lt;p&gt;&lt;ins&gt;&lt;strong&gt;Item Time to Live&lt;/strong&gt;&lt;/ins&gt; is a unique but underrated feature, which automatically deletes expired items from a table. This can be useful for managing temporary data or purging stale records, reducing storage costs and query overhead. This allows you to think of DynamoDB for a lot more use cases than just durable long-term data storage.
Consider a mobile gaming application that tracks user session data. By setting a TTL attribute on the session records in DynamoDB, you can ensure that expired sessions are automatically deleted from the table. Furthermore, you can use DynamoDB Streams in conjunction with AWS Lambda to trigger additional actions whenever an item is deleted, such as updating analytics or sending notifications.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;DynamoDB, in general, seems like a one size fits all, but it is far from it. While it offers several unique quirks that make it a powerful choice for scalable, low-latency data storage but it comes at. cost. Its flexible schema, automatic scaling, secondary indexes, and Time to Live feature provide developers with powerful tools to build efficient and dynamic applications. By combining DynamoDB with other AWS services, you can unleash its full potential and create robust, scalable solutions to meet your application&apos;s specific requirements.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Serverless Architecture 101: Key areas to look into from Day 0]]></title><description><![CDATA[You might have heard about Serverless recently. It has become increasingly popular, with more and more businesses adopting it as a way to‚Ä¶]]></description><link>https://mayankraj.com/blog/serverless-architecture-101</link><guid isPermaLink="false">https://mayankraj.com/blog/serverless-architecture-101</guid><pubDate>Mon, 05 Dec 2022 18:30:00 GMT</pubDate><content:encoded>&lt;p&gt;You might have heard about Serverless recently. It has become increasingly popular, with more and more businesses adopting it as a way to build and deploy applications. Moreover, developers are finding it easy to build applications with it. Serverless computing allows developers to focus on writing code, without worrying about the underlying infrastructure.&lt;/p&gt;
&lt;p&gt;Over the years, I&apos;ve built many applications with serverless components embedded into them. Today I prefer to use my serverless templates for even my hobby projects let alone API endpoints that process millions of requests. There are a few key areas that I always find myself coming back to. In this post, I&apos;ve collected 10 such areas that you should pay attention to when building serverless applications, especially using AWS services.&lt;/p&gt;
&lt;br/&gt;
&lt;hr&gt;
&lt;p&gt;Let&apos;s start with the three basics - API, Compute, and Storage.&lt;/p&gt;
&lt;h2&gt;1. API Endpoints&lt;/h2&gt;
&lt;p&gt;API Gateway is a fully managed service that makes it easy for developers to create, publish, maintain, monitor, and secure APIs at any scale. It acts as a ‚Äúfront door‚Äù for your serverless application, allowing you to define RESTful APIs and route requests to backend services. However, if GraphQL is more of your thing, look no further than AWS AppSync.&lt;/p&gt;
&lt;p&gt;For Example: If you want to build a serverless application that requires an API, you can use AWS API Gateway to define your RESTful APIs and route requests to your Lambda functions.&lt;/p&gt;
&lt;h2&gt;2. Compute&lt;/h2&gt;
&lt;p&gt;No brownie points for guessing it. Compute is the foundation of serverless architecture. AWS provides two main computing services: AWS Lambda and AWS Fargate. AWS Lambda is a computing service that lets you run code without provisioning or managing servers. Fargate is a serverless compute engine for containers that allows you to run containers without managing servers or clusters.
For Example: If you want to build a serverless application that requires a lot of computing power, you can use AWS Lambda to run your code. If you have your containers with you fargate may be better suited for you.&lt;/p&gt;
&lt;h2&gt;3. Storage&lt;/h2&gt;
&lt;p&gt;Serverless applications require storage for application data, logs, and other assets. AWS provides several storage services, including Amazon S3, Amazon DynamoDB, and Amazon Aurora serverless.
For Example: If you want to build a serverless application that requires a database, you can use Amazon DynamoDB to store your data.&lt;/p&gt;
&lt;br/&gt;
&lt;hr&gt;
&lt;p&gt;Now with basics out of the way, you have your POC in place. We now get into the interesting aspects of making this application ready for the wide and interesting audience of the public internet.&lt;/p&gt;
&lt;h2&gt;5. Breaking down the core logic:&lt;/h2&gt;
&lt;p&gt;Break down your application into smaller, focused functions to take full advantage of serverless scalability. Avoid creating monolithic functions that handle multiple tasks.
For example, in an e-commerce application, a lambda function for processing orders and another for sending email notifications would be ideal. You can club them with SQS and make the two logical flows async.&lt;/p&gt;
&lt;h2&gt;6. Events and more Events:&lt;/h2&gt;
&lt;p&gt;Always think of breaking into smaller modules and syncing them together with events. Make use of the event-driven architecture to trigger serverless functions. Utilize AWS services such as Amazon S3, Amazon DynamoDB, or Amazon Simple Notification Service (SNS) to trigger functions based on specific events.
For instance, when a new image is uploaded to an S3 bucket, you can automatically resize and optimize it using AWS Lambda.&lt;/p&gt;
&lt;h2&gt;7. Data and State Durability:&lt;/h2&gt;
&lt;p&gt;Serverless functions are inherently stateless, which means they do not maintain a session state. Use managed services like Amazon DynamoDB, Amazon Aurora Serverless, or Amazon Simple Queue Service (SQS) to persist and manage application state across invocations.&lt;/p&gt;
&lt;h2&gt;8. Balance Scalability with Concurrency :&lt;/h2&gt;
&lt;p&gt;Design your serverless application to handle concurrent invocations effectively. Configure the maximum concurrency limits for your functions to avoid resource exhaustion. AWS provides services like AWS Auto Scaling and Amazon API Gateway to automatically scale your serverless application based on demand.&lt;/p&gt;
&lt;h2&gt;9. Design for Cold Starts:&lt;/h2&gt;
&lt;p&gt;Serverless functions may experience latency due to cold starts when invoked infrequently. Employ strategies such as function warmers, provisioned concurrency, or keeping functions warm with periodic invocations. AWS Lambda provides provisioned concurrency to keep functions ready for instant response.&lt;/p&gt;
&lt;h2&gt;10. Distributed Tracing and Monitoring:&lt;/h2&gt;
&lt;p&gt;Ensure visibility into your serverless application by implementing distributed tracing and monitoring. AWS X-Ray allows you to trace requests as they flow across different serverless functions, helping you identify performance bottlenecks and optimize your application.&lt;/p&gt;
&lt;h2&gt;11. Security and Access Control:&lt;/h2&gt;
&lt;p&gt;Implement proper security measures to protect your serverless applications. Leverage AWS Identity and Access Management (IAM) for fine-grained access control. Apply security best practices, such as using secure API gateways, encrypting data at rest and in transit, and following least privilege principles.&lt;/p&gt;
&lt;h2&gt;12. Error Handling and Retry Mechanisms:&lt;/h2&gt;
&lt;p&gt;Design your serverless application to handle errors gracefully. Utilize features like AWS Step Functions for building resilient workflows, or implement retries with exponential backoff to handle transient failures. AWS Simple Notification Service (SNS) and Amazon Simple Queue Service (SQS) can be used for reliable event processing.&lt;/p&gt;
&lt;h2&gt;13. Cost Optimization:&lt;/h2&gt;
&lt;p&gt;Optimize the cost of running your serverless application. Configure auto-scaling policies based on demand to avoid over-provisioning. Use AWS Cost Explorer and AWS Budgets to monitor and analyze your serverless costs. Additionally, consider using AWS Lambda Layers to share code across functions and reduce duplication.&lt;/p&gt;
&lt;h2&gt;14. Integration with Existing Systems:&lt;/h2&gt;
&lt;p&gt;Leverage AWS services like AWS API Gateway and AWS EventBridge to seamlessly integrate your serverless application with existing systems. Use AWS Lambda as an integration layer to connect disparate components of your application architecture.&lt;/p&gt;
&lt;h2&gt;&lt;br/&gt;&lt;/h2&gt;
&lt;p&gt;Serverless is a great tool. But remember that at the end of the day, it&apos;s just another tool. You should not be looking at forcing the tools to do the job. Designing for serverless architecture requires careful consideration of various aspects to ensure scalability, reliability, and cost-effectiveness. By focusing on function granularity, event triggering, state management, scalability, and other key areas, you can harness the full potential of serverless computing. AWS provides a rich set of services that can be used to address these considerations and build highly efficient and scalable serverless applications.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[An Associate Director talks opportunities, flexibility, and work culture at CACTUS Tech]]></title><link>https://mayankraj.com/blog/cactustech-interview</link><guid isPermaLink="false">https://mayankraj.com/blog/cactustech-interview</guid><pubDate>Mon, 16 Aug 2021 19:40:46 GMT</pubDate><content:encoded></content:encoded></item><item><title><![CDATA[Python Building Blocks - Generators]]></title><link>https://mayankraj.com/blog/python-generators</link><guid isPermaLink="false">https://mayankraj.com/blog/python-generators</guid><pubDate>Thu, 15 Jul 2021 19:40:46 GMT</pubDate><content:encoded></content:encoded></item><item><title><![CDATA[Of Aspirations and Achievements- Front-end Intern to Solutions Architect in 3.5 Years]]></title><link>https://mayankraj.com/blog/career-update</link><guid isPermaLink="false">https://mayankraj.com/blog/career-update</guid><pubDate>Tue, 14 Jan 2020 19:40:46 GMT</pubDate><content:encoded></content:encoded></item><item><title><![CDATA[Demystifying JavaScript Closures]]></title><link>https://mayankraj.com/blog/javascript-closures</link><guid isPermaLink="false">https://mayankraj.com/blog/javascript-closures</guid><pubDate>Sat, 30 Nov 2019 19:40:46 GMT</pubDate><content:encoded></content:encoded></item><item><title><![CDATA[Managing Continuous Integration Pipelines with Jenkins]]></title><link>https://mayankraj.com/blog/cicd-with-jenkins</link><guid isPermaLink="false">https://mayankraj.com/blog/cicd-with-jenkins</guid><pubDate>Tue, 11 Jun 2019 19:40:46 GMT</pubDate><content:encoded></content:encoded></item><item><title><![CDATA[How To Build a Search Bar with RxJS]]></title><link>https://mayankraj.com/blog/searchbar-with-rxjs</link><guid isPermaLink="false">https://mayankraj.com/blog/searchbar-with-rxjs</guid><pubDate>Wed, 17 Apr 2019 19:40:46 GMT</pubDate><content:encoded></content:encoded></item><item><title><![CDATA[Generating Synthetic Music with JavaScript - Introduction to Neural Networks]]></title><link>https://mayankraj.com/blog/synthetic-music-with-neural-networks</link><guid isPermaLink="false">https://mayankraj.com/blog/synthetic-music-with-neural-networks</guid><pubDate>Wed, 17 Apr 2019 19:40:46 GMT</pubDate><content:encoded></content:encoded></item><item><title><![CDATA[Automating windows with COM object]]></title><description><![CDATA[A few weeks ago I got a project wherein I had to get various statistical data about a document. One of the important parameters was to get a‚Ä¶]]></description><link>https://mayankraj.com/blog/automation-with-windows-com</link><guid isPermaLink="false">https://mayankraj.com/blog/automation-with-windows-com</guid><pubDate>Sat, 01 Dec 2018 16:54:41 GMT</pubDate><content:encoded>&lt;p&gt;A few weeks ago I got a project wherein I had to get various statistical data about a document. One of the important parameters was to get a precise count of grammatical errors in the document. I tried to go the open source way and tested out &lt;a href=&quot;https://www.languagetool.org/&quot;&gt;LanguageTool&lt;/a&gt;, &lt;a href=&quot;http://proselint.com/&quot;&gt;PorseLink&lt;/a&gt; among others. None of these were up to the mark of the good old MS-Word.
So I had to now work on a way to problematically access Word, load a document in it and get the statistics.&lt;/p&gt;
&lt;p&gt;Python being versatile and great at memory management, we would be using it to control COM object and do what we need to do.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;This is the Part 1 of the two series post.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Part 1&lt;/strong&gt; : Introduction to &lt;code&gt;COMobject&lt;/code&gt;, initialization, examples etc&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Part 2&lt;/strong&gt; : Setting up a server environment. Making use of threads and opening using thread for each process. This is how to communicate with the &lt;code&gt;COMobject&lt;/code&gt; in a multi-thread environment as it cannot be passed to a thread directly.&lt;/p&gt;
&lt;hr&gt;
&lt;h1&gt;Before we dig deep, what is COMobject ?&lt;/h1&gt;
&lt;blockquote&gt;
&lt;p&gt;The Microsoft Component Object Model (COM) is a platform-independent, distributed, object-oriented system for creating binary software components that can interact. COM is the foundation technology for Microsoft&apos;s OLE (compound documents), ActiveX (Internet-enabled components), as well as others. &lt;a href=&quot;https://msdn.microsoft.com/en-us/library/windows/desktop/ms694363(v=vs.85).aspx&quot;&gt;read more...&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In a nutshell it can be used to control various aspects of Windows. We would be focusing on using the &lt;code&gt;COMobject&lt;/code&gt; to control MS-Office applications like Word and Excel. Although it is not limited to just MS-Office applications, it can be used to communicate with other softwares like IE (if you&apos;re still into it...)&lt;/p&gt;
&lt;p&gt;You can do things like :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Create triggers to perform various tasks
&lt;ul&gt;
&lt;li&gt;Add new rows to an excel sheet in real time with the current scores of a game. This excel sheet can then have some complex algorithms to predict which team would win by performing calculations on all the rows. Although it can be done with implementation in even NodeJS but we don&apos;t want to take the pain to port the functions/macros from Excel to JS&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Log the current changes made by the user XYZ in the database&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The possibilities are limitless. I guess you already have a use case in mind and landing to this page to know the process, if not it&apos;s always good to know if there is possibility to get a certain functionality done.&lt;/p&gt;
&lt;h1&gt;Python and COM&lt;/h1&gt;
&lt;p&gt;We will need the following tools to communicate with MS-Word :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;MS Office or Specific applications already installed&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://pypi.python.org/pypi/pywin32&quot;&gt;PyWin32 library&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;code&gt;PyWin32&lt;/code&gt; is a great library that gives us the same set of methods/properties that are exposed by COM which are natively in Visual Basic for Applications (VBA).&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;NOTE: I&apos;m using Python3 in the code samples in this guide.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;Let&apos;s start&lt;/h2&gt;
&lt;p&gt;To get hold of a COM object&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;import win32com.client

# for MS-Word
word = win32.gencache.EnsureDispatch(&apos;Word.Application&apos;)
# OR
word = win32com.client.DispatchEx(&apos;Word.Application&apos;)

# for MS-Excel
excel = win32.gencache.EnsureDispatch(&apos;Excel.Application&apos;)
# OR
excel = win32com.client.DispatchEx(&apos;Excel.Application&apos;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There are some key differences to be noted here&lt;/p&gt;
&lt;p&gt;&lt;code&gt;EnsureDispatch&lt;/code&gt; : In dead simple terms, it makes sure that a object which references the specified application is returned. If the application is already open, it will return the same instance, if not it will start a instance and return it.
It is useful in cases where you would want to make use of single application that holds certain meta-data, over the life of the process.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;DispatchEx&lt;/code&gt; : For each call, you would get a new object returned. This would mean that if you call it 7 times, you would see 7 instances of MS-Word in task manager.
It makes sense to get independent instances when you would want to handle each process independently and close the application when one process completes.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Understand that if you run a web-server that takes in data, puts it in an Excel, runs a macro and return a result. You would want to have a dedicated instance of Excel for each process so that you can close it as soon as the response is ready. If you used &lt;code&gt;EnsureDispatch&lt;/code&gt; or &lt;code&gt;Dispatch&lt;/code&gt;, that would mean that at the end of each process, you would have to check if any other process is in progress, if not shut down the application.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;It&apos;s requires a bit extra memory but helps to keep memory leak in check as using same application instance to load up multiple files that do not require each others data, means that with each load, some meta-data is loaded which is not cleared when closing the process and it builds up over time. &lt;em&gt;We will cover this aspect in detail in the Part-2 of the post.&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Coming back to the point, let&apos;s go ahead.&lt;/p&gt;
&lt;p&gt;Now that we have the &lt;code&gt;COMobject&lt;/code&gt; we can use it a open a Word Document.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;doc = word.Documents.Open( os.path.join( os.getcwd(), &apos;path/to/files/&apos;, filename), ReadOnly=True)
&lt;/code&gt;&lt;/pre&gt;
&lt;blockquote&gt;
&lt;p&gt;NOTE : As you might have had guessed, you can use the same &lt;code&gt;word&lt;/code&gt; object to open multiple &lt;code&gt;doc&lt;/code&gt; objects. This is what I was referring to using same application to open multiple documents in the last paragraph&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;p&gt;At this point, we can refer to Microsoft&apos;s documentation to get gist of various properties &amp;#x26; functions available.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://msdn.microsoft.com/en-us/library/bb244391(v=office.12).aspx&quot;&gt;&lt;strong&gt;Word 2007 Developers Reference&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://msdn.microsoft.com/en-us/library/bb244515(v=office.12).aspx&quot;&gt;&lt;strong&gt;Word Object Model reference&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://msdn.microsoft.com/en-us/library/bb244569(v=office.12).aspx&quot;&gt;&lt;strong&gt;Application Object&lt;/strong&gt;&lt;/a&gt; : List of methods and properties available&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Let&apos;s have look at some usage examples:&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Make the application window invisible :&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;word.Visible = False
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;To add a new Document&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;doc = word.Documents.Add()
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;To get all the grammatical or spelling errors&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;grammaticalErrors = doc.GrammaticalErrors
spellingErrors = doc.doc.SpellingErrors

#or to simple get the count
grammaticalErrorsCount = doc.GrammaticalErrors.Count
spellingErrorsCount = doc.SpellingErrors.Count
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If you have a look at the &lt;a href=&quot;https://msdn.microsoft.com/en-us/library/bb237490(v=office.12).aspx&quot;&gt;&lt;strong&gt;Word BuiltInProperty&lt;/strong&gt;&lt;/a&gt;, you&apos;ll see you can do the following&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;wordCount = int(doc.BuiltInDocumentProperties(15))
characterCount = int(doc.BuiltInDocumentProperties(16))
paragraphCount = int(doc.BuiltInDocumentProperties(24))
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;or do something much more complex as&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;characterPerWord = doc.ReadabilityStatistics(&quot;Characters per Word&quot;).Value
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;or something as simple as&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;shapeCount = doc.Shapes.Count
tableCount = doc.Tables.Count
sentenceCount = doc.Sentences.Count
tableOfContentCount = doc.TablesOfContents.Count

#loop through each paragraphs
for paras in doc.Paragraphs:
    # paras will now be each individual paragraph

&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h1&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;As you can see the possibilities are endless. MS-Office tools are pretty powerful in what they do. We did not even dig into the excel territory. Majority of the questions on stackoverflow are based on excel as automating tasks there makes can be of great use.&lt;/p&gt;
&lt;p&gt;In the next post we will focus on how to wrap all this up into dedicated thread for each process and word with COMobject in threads.&lt;/p&gt;</content:encoded></item></channel></rss>